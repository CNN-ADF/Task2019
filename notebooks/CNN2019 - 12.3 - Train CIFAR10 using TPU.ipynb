{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN2019 - 12.3 - Train CIFAR10 using TPU.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hPwFEN34mNUP","colab_type":"text"},"source":["![title](https://image.ibb.co/erDntK/logo2018.png)\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sjlcHwermNUS","colab_type":"text"},"source":["\n","# Task 12 part 3/3 - Train CIFAR10 using TPU\n","\n","In this last part of assignment you will try to train a five layer CNN on CIFAR-10 dataset using free 8 TPUs provided by google\n","\n","The goals of this assignment are as follows:\n","\n","<pre>* train a five layer CNN using TPU</pre>\n","\n","---\n","<font size=4 color=\"blue\">Note: \n","  <br>Before running this file, <br>Close all other Google Colaboratory tabs that are still active<br>\n","as it may hinder the TPU processing\n","  \n","---"]},{"cell_type":"markdown","metadata":{"id":"6VAE_sE-Bgk1","colab_type":"text"},"source":["---\n","---\n","#[Part 0] Import Libraries and Load Data"]},{"cell_type":"markdown","metadata":{"id":"_AgIza0ZupR2","colab_type":"text"},"source":["---\n","## 0 - Acceleration Setting\n","\n","This time we will check the ability of TensorFlow if it is run with TPU acceleration.\n","\n","For that, make sure that this Google Colab use **TPU** Runtime acceleration.\n","* Select the Runtime menu\n","* Change Runtime Type\n","* Choose **TPU**\n","\n","<img src = \"https://i.ibb.co/6t5CCyL/tpu.png\" align = \"center\">\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3iIKvXgjjCn-","colab_type":"text"},"source":["---\n","## 1 - Install TensorFlow 2 ?\n","\n","We'd love to use TensorFlow 2 for this exercise as well\n","\n","But unfortunately, up to the time this exercise is published, the TPU support for Keras API is not yet completed, and still under development\n","\n","So we're back using Tensorflow 1.15 \n","\n",":("]},{"cell_type":"code","metadata":{"id":"VitP-OLAjCGz","colab_type":"code","colab":{}},"source":["# !pip install tensorflow-gpu -q"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NOPPPUZXi5EX","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","tf.__version__"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aIpLk-Iej1RC"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n"," '1.15.0'"]},{"cell_type":"code","metadata":{"id":"HyeXRIycxxeH","colab_type":"code","colab":{}},"source":["import torch\n","torch.__version__"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BE765j8Ixynl"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n"," '1.3.0'"]},{"cell_type":"markdown","metadata":{"id":"DvPSXMEIaFm1","colab_type":"text"},"source":["---\n","## 2 - Import Libraries\n","Import required libraries"]},{"cell_type":"code","metadata":{"id":"4KOPbytzogWG","colab_type":"code","colab":{}},"source":["import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import pprint\n","\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import Model\n","from tensorflow.keras.models import Sequential\n","\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import GlobalAveragePooling2D\n","from tensorflow.keras.applications.vgg16 import VGG16\n","\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.utils import plot_model\n","\n","%matplotlib inline\n","np.set_printoptions(precision=7)\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SF71bN55cZzi","colab_type":"text"},"source":["Write down your Name and Student ID"]},{"cell_type":"code","metadata":{"id":"S5yg44U8cZzk","colab_type":"code","colab":{}},"source":["## --- start your code here ----\n","\n","NIM = ??\n","Nama = ??\n","\n","## --- end your code here ----"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fTMPdtW1mNVv","colab_type":"text"},"source":["---\n","## 3 - Load CIFAR-10"]},{"cell_type":"code","metadata":{"id":"HJMZF1BZmNVw","colab_type":"code","colab":{}},"source":["(X_train_ori, y_train), (X_test_ori, y_test) = tf.keras.datasets.cifar10.load_data()\n","\n","class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c57WBdtqmNVz","colab_type":"text"},"source":["---\n","## 4 - Split Validation Data"]},{"cell_type":"code","metadata":{"id":"5vuvkKCdmNV1","colab_type":"code","cellView":"both","colab":{}},"source":["X_val_ori = X_train_ori[-10000:,:]\n","y_val     = y_train[-10000:]\n","\n","X_train_ori = X_train_ori[:-10000, :]\n","y_train     = y_train[:-10000]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WJZisKPImNV4","colab_type":"text"},"source":["---\n","## 5 - Normalize and Reshape Data"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"TwP9wbYLmNV5","colab_type":"code","cellView":"both","colab":{}},"source":["X_train = X_train_ori.astype('float32')\n","X_val   = X_val_ori.astype('float32')\n","X_test  = X_test_ori.astype('float32')\n","\n","mean_image = X_train.mean(axis=(0, 1, 2), keepdims=True)\n","std_image = X_train.std(axis=(0, 1, 2), keepdims=True)\n","\n","X_train = (X_train - mean_image) /std_image\n","X_val = (X_val - mean_image) /std_image\n","X_test = (X_test - mean_image) /std_image\n","\n","X_train = X_train.astype('float32')\n","X_val = X_val.astype('float32')\n","X_test = X_test.astype('float32')\n","\n","\n","print('X_train.shape =',X_train.shape)\n","print('X_val.shape   =',X_val.shape)\n","print('X_test.shape  =',X_test.shape)\n","\n","y_train = y_train.ravel()\n","y_val   = y_val.ravel()\n","y_test  = y_test.ravel()\n","\n","print('\\ny_train.shape =',y_train.shape)\n","print('y_val.shape   =',y_val.shape)\n","print('y_test.shape  =',y_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GpPgnChbl8jj","colab_type":"text"},"source":["one hot the label"]},{"cell_type":"code","metadata":{"id":"neQU8KqDIn1_","colab_type":"code","colab":{}},"source":["y_train_hot = to_categorical(y_train, 10)\n","y_val_hot   = to_categorical(y_val, 10)\n","y_test_hot  = to_categorical(y_test, 10)\n","\n","print('y_train_hot.shape =',y_train_hot.shape)\n","print('y_val_hot.shape   =',y_val_hot.shape)\n","print('y_test_hot.shape  =',y_test_hot.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VKAWDMHpkSjy","colab_type":"text"},"source":["---\n","## 6 - Helper Function"]},{"cell_type":"code","metadata":{"id":"6qS-rDCAQCjL","colab_type":"code","colab":{}},"source":["def plot_history(history):\n","  plt.rcParams['figure.figsize'] = [12, 4]\n","  plt.subplots_adjust(wspace=0.2)\n","\n","  plt.subplot(121)\n","  # Plot training & validation accuracy values\n","  plt.plot(history.history['acc'])\n","  plt.plot(history.history['val_acc'])\n","  plt.title('Model accuracy')\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train', 'Val'])\n","\n","  plt.subplot(122)\n","  # Plot training & validation loss values\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Model loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train', 'Val'])\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pKghE730YdkF"},"source":["---\n","---\n","# [Part 1] Device Acceleration Checking"]},{"cell_type":"markdown","metadata":{"id":"3XY9l5ODpJp5","colab_type":"text"},"source":["## 1 - GPU Availability Check\n","\n","Next, let's check TensorFlow and PyTorch's ability to utilize GPU capabilities\n","\n","**Because we set this Google Colab to with TPU acceleration, there will be no GPU name displayed**"]},{"cell_type":"code","metadata":{"id":"_4a2I2ZKpE4q","colab_type":"code","colab":{}},"source":["print('Using GPU:', tf.test.is_gpu_available())\n","\n","if tf.test.is_gpu_available():\n","  print('GPU name :', tf.test.gpu_device_name())\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Q65ikAWtxXOz"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","    Using GPU: False"]},{"cell_type":"code","metadata":{"id":"4XeTg2E9oxaD","colab_type":"code","colab":{}},"source":["print('Using GPU:',torch.cuda.is_available())\n","\n","if torch.cuda.is_available():\n","  print('GPU name :',torch.cuda.get_device_name(0))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"O0vI9QBPxsRD"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","    Using GPU: False"]},{"cell_type":"markdown","metadata":{"id":"afwrUonUphEu","colab_type":"text"},"source":["## 2 - TPU Availability Check\n","\n","Then, let's check TensorFlow's ability to utilize TPU capabilities \n","\n","**Because we set this Google Colab to run with TPU acceleration, it will show that Google provided us with 8 Free TPUs**"]},{"cell_type":"code","metadata":{"id":"C3wzT-jVoxXd","colab_type":"code","colab":{}},"source":["if 'COLAB_TPU_ADDR' not in os.environ:\n","  print('Not connected to a TPU runtime')\n","  \n","else:\n","  \n","  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","  print ('TPU address is', tpu_address)\n","\n","  # for tf 2.x\n","  # tf.config.experimental_connect_to_host(tpu_address)\n","  # devices=tf.config.experimental_list_devices()\n","  \n","  # for tf 1.x  \n","  with tf.Session(tpu_address) as session:\n","    devices = session.list_devices()\n","    \n","  print('TPU devices:') \n","  print(*devices, sep=\"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IWNvMRIMyNHW"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","    TPU address is grpc://10.xxx.xxx.xxx:xxxx\n","    TPU devices: \n","     /job:tpu_worker/replica:0/task:0/device:CPU:0\n","     /job:tpu_worker/replica:0/task:0/device:XLA_CPU:0\n","     /job:tpu_worker/replica:0/task:0/device:TPU:0\n","               ... **you should see 8 TPU devices from id device:TPU:0 to 7** ...\n","     /job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0"]},{"cell_type":"markdown","metadata":{"id":"fNIfgK0sMm9V","colab_type":"text"},"source":["---\n","---\n","# [Part 2] Train 5-layer ConvNet\n","\n","Now let's build and train our model\n","\n"]},{"cell_type":"code","metadata":{"id":"zbwP7s5tipIX","colab_type":"code","colab":{}},"source":["from tensorflow.keras.models import Sequential\n","\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"53aIJsYp3b1x","colab_type":"text"},"source":["---\n","## 1 - Model Builder"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EJG9Bgo3zEzK"},"source":["#### <font color='red'>**EXERCISE**: </font>\n","**Define a ConvNet Model as follow**\n","\n","    * 32 @ Conv 3x3 using relu and padding same\n","    * 32 @ Conv 3x3 using relu and padding same\n","    * Max Pool\n","    * 64 @ Conv 3x3 using relu and padding same    \n","    * Max Pool\n","    * Flatten\n","    * Dense 200 using relu\n","    * Dense 10 using softmax\n","    \n","    then compile using categorical crossentropy and optimizer adam\n"]},{"cell_type":"code","metadata":{"id":"3BKumIipod3p","colab_type":"code","colab":{}},"source":["# for tf 1.x\n","def FiveConvNet(name):\n","  \n","  resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n","  tf.contrib.distribute.initialize_tpu_system(resolver)\n","  strategy = tf.contrib.distribute.TPUStrategy(resolver)\n","  \n","  print('\\n\\n-----------------------------------------------------')\n","  \n","  with strategy.scope():\n","    \n","    model = Sequential([\n","\n","        ??, # conv\n","        ??, # conv\n","        ??, # pool\n","        ??, # conv\n","        ??, # pool\n","        ??, # flatten\n","        ??, # dense\n","        ??  # dense\n","\n","    ], name = name) \n","    \n","    model.compile(??,  ??, metrics=['accuracy'])\n","  \n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qyQKN3hJz0MH","colab_type":"text"},"source":["---\n","## 2 - Define Model"]},{"cell_type":"code","metadata":{"id":"a_GWjiaQz-mC","colab_type":"code","colab":{}},"source":["model = FiveConvNet('using_TPU')\n","\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_1PLi1YP0Fjh"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Model: \"using_TPU\"\n","conv2d (Conv2D)              (None, 32, 32, 32)        896       \n","...\n","dense_? (Dense)              (None, 10)                2010        \n","\n","Total params: 850,050\n","Trainable params: 850,050\n","Non-trainable params: 0\n","_________________________________________________________________"]},{"cell_type":"markdown","metadata":{"id":"0BjRQudj0Qdg","colab_type":"text"},"source":["---\n","## 3 - Train Model\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Cqz2YhpC5yJx"},"source":["#### <font color='red'>**EXERCISE**: </font>\n","**Train the model for 8 epochs using batch size 200**\n","\n","**Don't forget to feed the validation data**\n","\n","\n","    "]},{"cell_type":"code","metadata":{"id":"YTMMAyn2jKDm","colab_type":"code","colab":{}},"source":["import time\n","\n","num_epochs = ??\n","batch_size = ??\n","\n","tic = time.time()\n","\n","history = model.fit(??, ??, \n","                    ??,\n","                    ??, \n","                    ??, \n","                    verbose=2)\n","\n","toc = time.time()\n","\n","print('\\n\\ntraining speed = %.2f seconds' % (toc-tic))\n","print('training speed = %.2f minutes' % ((toc-tic)/60))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9zkCeIn71Pdi"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Your model should run in about 8 seconds per epoch\n","it's slower than using GPU\n","and somehow the speed is decreasing along the epoch\n","\n","This happened because the TPU is not yet effectively implemented for Keras API"]},{"cell_type":"markdown","metadata":{"id":"c4NYoYbd0guE","colab_type":"text"},"source":["---\n","## 4 - Visualize Training"]},{"cell_type":"code","metadata":{"id":"-gUP_tmW0eBZ","colab_type":"code","colab":{}},"source":["plot_history(history)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZRYQUCc70kuB","colab_type":"text"},"source":["---\n","## 5 - Evaluate Model"]},{"cell_type":"code","metadata":{"id":"UWby1QQhkeL-","colab_type":"code","colab":{}},"source":["val_scores   = model.evaluate(X_val, y_val_hot, verbose=2)\n","test_scores  = model.evaluate(X_test, y_test_hot, verbose=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1c7Axqji8o1o","colab_type":"code","colab":{}},"source":["print('val  acc %.2f%%' % (val_scores[1]*100))\n","print('test acc %.2f%%' % (test_scores[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lNsYt9oG67vd"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","You should get around 70% accuracy on data test\n","tough the model is overfit"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_LuEQe63EsWH"},"source":["---\n","---\n","# [Part 3] Train VGG16\n","\n","To clearly compare the TPU performance in speeding up the computation, let's use the VGG16 to train CIFAR10 dataset"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"s_64TzyVEsWY"},"source":["---\n","## 1 - Model Builder"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GDpHC2dOPD_P"},"source":["#### <font color='red'>**EXERCISE**: </font>\n","**Define a ConvNet Model as follow**\n","\n","    * vgg16 model with weights=None, include_top=False, and input_shape=(32,32,3)\n","    * get layer 'block4_conv3' output\n","    * GlobalAveragePooling2D\n","    * Dense 200 using relu\n","    * Dense 10 using softmax\n","    \n","    use Functional API,\n","    then compile using categorical crossentropy and optimizer adam\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"t53VFCqLEsWe","colab":{}},"source":["from tensorflow.keras.applications.vgg16 import VGG16\n","\n","def CifarVGG(name):\n","  \n","  resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n","  tf.contrib.distribute.initialize_tpu_system(resolver)\n","  strategy = tf.contrib.distribute.TPUStrategy(resolver)\n","  \n","  with strategy.scope():\n","    \n","    # load empty vgg16 no top with input (32,32,3)\n","    model = ??\n","\n","    # get 'block4_conv3' output using model.get_layer()\n","    x = ??\n","\n","    # global average pooling\n","    x = ??\n","\n","    # dense 200\n","    x = ??\n","\n","    # dense 10\n","    prediction = ??\n","\n","    # instantiate model\n","    myModel = Model(inputs=??, outputs=??, name=name)\n","    \n","    myModel.compile(??,  ??, metrics=['accuracy'])\n","  \n","  return myModel\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"byzN39tEEsWj"},"source":["---\n","## 2 - Define Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QgS0fYAYEsWk","colab":{}},"source":["model = CifarVGG('VGG_using_TPU')\n","\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"smukVtarPhxZ"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Model: \"VGG_using_TPU\"\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","...\n","dense_? (Dense)              (None, 200)               102600    \n","prediction (Dense)           (None, 10)                2010      \n","\n","Total params: 7,739,874\n","Trainable params: 7,739,874\n","Non-trainable params: 0\n","_________________________________________________________________"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vqR50hkmEsWr"},"source":["---\n","## 3 - Train Model\n","\n","Now let's train it for 10 epoch and greater batch size of 1000\n","\n","Notice that we're not using validation data\n","\n","TPU acceleration using Keras API, at the moment, is still experimental. And passing validation data in `.fit()` function slows down the process considerably"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4C5ZSb50EsWu","colab":{}},"source":["import time\n","\n","num_epochs = 10\n","batch_size = 1000\n","\n","tic = time.time()\n","\n","history = model.fit(X_train, y_train_hot, \n","                    epochs=num_epochs, \n","                    batch_size=batch_size, \n","                    verbose=2)\n","\n","toc = time.time()\n","\n","print('\\n\\ntraining speed = %.2f seconds' % (toc-tic))\n","print('training speed = %.2f minutes' % ((toc-tic)/60))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IuZeH70eEsW0"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Your model should run in about 5 seconds per epoch\n","\n","about 4x faster than using GPU"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8xOOW3g0EsW7"},"source":["---\n","## 4 - Evaluate Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"suf2M5ZjEsW8","colab":{}},"source":["val_scores   = model.evaluate(X_val, y_val_hot, verbose=2)\n","test_scores  = model.evaluate(X_test, y_test_hot, verbose=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7wCYO_4fHbUz","colab":{}},"source":["print('val  acc %.2f%%' % (val_scores[1]*100))\n","print('test acc %.2f%%' % (test_scores[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"t29orKJ8EsXC"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","You should get around 70% accuracy on data test\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aQqQ_gcO92ub"},"source":["\n","---\n","\n","# Congratulation, You've Completed Exercise 12 part 3/3\n","\n","<p>Copyright &copy;  <a href=https://www.linkedin.com/in/andityaarifianto/>2019 - ADF</a> </p>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bvBk-u7_92ub"},"source":["![footer](https://image.ibb.co/hAHDYK/footer2018.png)"]}]}